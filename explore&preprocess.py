# -*- coding: utf-8 -*-
"""Explore&Preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o0h4XDcUDXUp1ujBTnL-bUDLteaEJ2Qg
"""

from google.colab import files
files.upload() # Choose the kaggle.json file you just downloaded

import kagglehub

# Download latest version
path = kagglehub.dataset_download("dtrnngc/ua-detrac-dataset")

print("Path to dataset files:", path)

!pip install opencv-python-headless matplotlib albumentations -q

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random
import albumentations as A # Optional, but recommended for advanced augmentation

# Function to display images in Colab
def display_image(image, title="Image"):
    plt.figure(figsize=(10, 8))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if len(image.shape) == 3 else image, cmap='gray')
    plt.title(title)
    plt.axis('off')
    plt.show()

# --- !!! IMPORTANT: ADJUST THESE PATHS !!! ---
dataset_base_path = "/content/drive/MyDrive/UA_DATA" # Or your actual path

# Example: Assuming a structure like images/train/MVI_20011_img00001.jpg
# and labels/train/MVI_20011_img00001.txt
# You'll need to find a valid image and its label file from your dataset.
try:
    # Attempt to find the 'train' subdirectories
    image_train_dir = os.path.join(dataset_base_path, "images", "train")
    label_train_dir = os.path.join(dataset_base_path, "labels", "train")

    if not os.path.isdir(image_train_dir) or not os.path.isdir(label_train_dir):
        # Fallback if the 'images/train' structure isn't found directly
        # This might happen if the Kaggle dataset has a different top-level folder
        # For example, if everything is under a "DETRAC_Upload" like folder:
        potential_top_folder = ""
        for item in os.listdir(dataset_base_path):
            if os.path.isdir(os.path.join(dataset_base_path, item)) and "upload" in item.lower(): # Heuristic
                potential_top_folder = item
                break
        if potential_top_folder:
             image_train_dir = os.path.join(dataset_base_path, potential_top_folder, "images", "train")
             label_train_dir = os.path.join(dataset_base_path, potential_top_folder, "labels", "train")


    if not os.path.isdir(image_train_dir) or not os.path.isdir(label_train_dir):
         raise FileNotFoundError("Could not find train image/label directories. Please verify the structure and update paths.")

    # Get the first image and label file from the train directories
    sample_image_name = sorted([f for f in os.listdir(image_train_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])[0]
    sample_label_name = os.path.splitext(sample_image_name)[0] + ".txt"

    sample_image_path = os.path.join(image_train_dir, sample_image_name)
    sample_label_path = os.path.join(label_train_dir, sample_label_name)

    if not os.path.exists(sample_image_path) or not os.path.exists(sample_label_path):
        raise FileNotFoundError(f"Sample image or label not found. Checked:\n{sample_image_path}\n{sample_label_path}")

    print(f"Using sample image: {sample_image_path}")
    print(f"Using sample label: {sample_label_path}")

except IndexError:
    print("Error: Could not find any image files in the specified training directory.")
    print(f"Please check the path: {image_train_dir}")
    sample_image_path = None
except FileNotFoundError as e:
    print(f"Error: {e}")
    print(f"Please ensure your 'dataset_base_path' ('{dataset_base_path}') is correct and contains the expected 'images/train' and 'labels/train' subdirectories, or adjust the logic to find your files.")
    sample_image_path = None


# Load the sample image
if sample_image_path:
    image = cv2.imread(sample_image_path)
    if image is not None:
        original_height, original_width = image.shape[:2]
        print(f"Original image dimensions: {original_width}x{original_height}")
        display_image(image.copy(), "Original Sample Image") # Display a copy
    else:
        print(f"Error: Could not read the sample image at {sample_image_path}")

#resize the image

if 'image' in locals() and image is not None: # Check if image was loaded
    target_size = (640, 640) # Example target size, common for YOLO
    resized_image = cv2.resize(image, target_size)
    resized_height, resized_width = resized_image.shape[:2]

    print(f"Resized image dimensions: {resized_width}x{resized_height}")
    display_image(resized_image, f"Resized Image ({resized_width}x{resized_height})")

    # Note: No changes needed to YOLO format labels for a simple resize.
    # The normalized coordinates x_center, y_center, width, height
    # are still valid relative to the new image dimensions.
else:
    print("Sample image not loaded. Skipping resize demonstration.")

#normalize the image

if 'resized_image' in locals(): # Check if resized_image exists
    # Normalize to [0, 1]
    normalized_image = resized_image.astype(np.float32) / 255.0

    print(f"Normalized image pixel value range: min={normalized_image.min()}, max={normalized_image.max()}")
    # Note: Displaying a float image normalized to 0-1 with plt.imshow is fine.
    # If you were to save it or view with cv2.imshow, you might need to scale back to 0-255 and uint8.
    display_image(normalized_image, "Normalized Image (pixels 0-1)")
else:
    print("Resized image not available. Skipping normalization demonstration.")

#random occulusions

if 'normalized_image' in locals(): # Check if normalized_image exists
    # Work on a copy
    image_for_occlusion = normalized_image.copy()
    img_h, img_w = image_for_occlusion.shape[:2]

    # Parameters for occlusion
    num_occlusions = random.randint(1, 3) # Add 1 to 3 occluding blocks
    for _ in range(num_occlusions):
        occ_h = random.randint(int(img_h * 0.05), int(img_h * 0.2)) # Occlusion height
        occ_w = random.randint(int(img_w * 0.05), int(img_w * 0.2)) # Occlusion width
        x1 = random.randint(0, img_w - occ_w)
        y1 = random.randint(0, img_h - occ_h)

        # Draw a black rectangle (occlusion)
        # If image_for_occlusion is float (0-1), occlude with 0.0
        # If it were uint8 (0-255), occlude with (0,0,0)
        image_for_occlusion[y1:y1+occ_h, x1:x1+occ_w] = 0.0

    display_image(image_for_occlusion, "Image with Random Occlusion")
else:
    print("Normalized image not available. Skipping occlusion augmentation.")

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import os

# --- !!! IMPORTANT: SET THIS TO YOUR ACTUAL best.pt PATH !!! ---
path_to_your_trained_model = "/content/runs/detect/yolov8s_ua_detrac_run1/weights/best.pt"

# Load your custom trained model
model = YOLO(path_to_your_trained_model)
print(f"Custom trained model loaded from {path_to_your_trained_model}")

# Function to display images (if you don't have it in the current cell)
def display_image_array(image_array, title="Image"):
    plt.figure(figsize=(10, 8))
    # Assuming image_array is in RGB format if it's a NumPy array
    plt.imshow(image_array)
    plt.title(title)
    plt.axis('off')
    plt.show()

if 'path_to_your_test_video' in locals() and path_to_your_test_video and os.path.exists(path_to_your_test_video):
    print(f"\nPerforming inference on video: {path_to_your_test_video}...")
    print("This might take a while depending on video length and model size.")

    # Perform detection on the video
    # save=True will save the output video with detections drawn.
    # stream=True is recommended for videos as it processes frame by frame, saving memory.
    # conf: confidence threshold for detections (e.g., 0.25 means only show detections with >25% confidence)
    # iou: IoU threshold for Non-Maximum Suppression

    output_video_filename = os.path.basename(path_to_your_test_video).replace('.', '_processed.')

    results_generator = model(
        source=path_to_your_test_video,
        stream=True, # Process as a stream
        save=True,   # Save the output video with drawn detections
        conf=0.3,    # Optional: Adjust confidence threshold (0.0 to 1.0)
        iou=0.5,     # Optional: Adjust IoU threshold for NMS (0.0 to 1.0)
        name="video_inference_run" # This will create a folder like runs/detect/video_inference_run
    )

    # Iterate through the results generator if you want to do something with each frame's results
    # For just saving the video, the model(..., save=True) call handles it.
    # The actual processed video path will be inside 'runs/detect/video_inference_run/'

    processed_video_path = ""
    print("\nProcessing video frames (output will be saved automatically by YOLOv8 if save=True)...")
    frame_count = 0
    for result in results_generator:
        frame_count += 1
        # result.plot() # You could get the annotated frame here if you wanted to display it live (slow for many frames)
        # boxes = result.boxes # Access raw box data for this frame for custom logic (like counting)
        if frame_count % 50 == 0: # Print progress every 50 frames
            print(f"  Processed {frame_count} frames...")

        # The first time through, get the path where YOLO is saving the video
        if not processed_video_path and hasattr(result, 'save_dir') and result.save_dir:
            # Construct the likely path to the saved video file
            # YOLO usually saves it with the original filename in the save_dir
            original_video_name = os.path.basename(path_to_your_test_video)
            processed_video_path = os.path.join(result.save_dir, original_video_name)


    print(f"\nVideo processing complete.")
    if os.path.exists(processed_video_path):
        print(f"Processed video should be saved at: {processed_video_path}")

        # Optional: Display the processed video in Colab (works for reasonably small MP4s)
        # This might not work if the video is too long or Colab has issues rendering
        try:
            print("\nAttempting to display the processed video in Colab (first 20MB)...")
            mp4 = open(processed_video_path,'rb').read(20*1024*1024) # Read first 20MB
            data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
            display(HTML(f"""
            <video width=600 controls>
                  <source src="{data_url}" type="video/mp4">
            </video>
            """))
            print(f"If video doesn't play, download it from: {processed_video_path}")
        except Exception as e:
            print(f"Could not display video in Colab: {e}")
            print(f"You can download it from: {processed_video_path}")
            print("Use the Colab file explorer (folder icon on the left) to navigate and download.")

    else:
        print("Processed video path could not be determined or file does not exist.")
        print("Please check the 'runs/detect/video_inference_run/' directory manually using the file explorer.")

else:
    print("Test video path is not set or file does not exist.")
    print("Please ensure 'path_to_your_test_video' is correctly defined and the file is accessible.")

!pip install opencv-python-headless matplotlib albumentations -q

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random
import albumentations as A # Optional, but recommended for advanced augmentation

# Function to display images in Colab
def display_image(image, title="Image"):
    plt.figure(figsize=(10, 8))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if len(image.shape) == 3 else image, cmap='gray')
    plt.title(title)
    plt.axis('off')
    plt.show()